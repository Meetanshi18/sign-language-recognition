{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train = pd.read_csv('C:/Users/meeta/Desktop/TSWE2019/sign-language-recognition/dataset/sign_mnist_train.csv', header = 0)\n",
    "test = pd.read_csv('C:/Users/meeta/Desktop/TSWE2019/sign-language-recognition/dataset/sign_mnist_test.csv', header = 0)\n",
    "\n",
    "def getProcessedData(train, test):\n",
    "    \n",
    "    y_train = train['label'].values\n",
    "    y_test = test['label'].values\n",
    "\n",
    "    x_train = train.drop(['label'],axis=1)\n",
    "    x_test = test.drop(['label'], axis=1)\n",
    "\n",
    "    x_train = np.array(x_train.iloc[:,:])\n",
    "    x_train = np.array([np.reshape(i, (28, 28)) for i in x_train])\n",
    "\n",
    "    x_test = np.array(x_test.iloc[:,:])\n",
    "    x_test = np.array([np.reshape(i, (28, 28)) for i in x_test])\n",
    "    \n",
    "    return normalizeData(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train/255\n",
    "    x_test = x_test/255\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = getProcessedData(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 27455\n",
      "Test examples: 7172\n",
      "X_train shape\" (27455, 28, 28)\n",
      "y_train shape\" (27455, 25)\n",
      "X_test shape\" (7172, 28, 28)\n",
      "y_test shape\" (7172, 25)\n",
      "(27455, 28, 28, 1)\n",
      "(27455, 25)\n"
     ]
    }
   ],
   "source": [
    "print('Training examples:',x_train.shape[0])\n",
    "print('Test examples:',x_test.shape[0])\n",
    "\n",
    "print('X_train shape\"',x_train.shape)\n",
    "print('y_train shape\"',y_train.shape)\n",
    "print('X_test shape\"',x_test.shape)\n",
    "print('y_test shape\"',y_test.shape)\n",
    "\n",
    "x_train = x_train.reshape((27455, 28, 28, 1))\n",
    "x_test = x_test.reshape((7172, 28, 28, 1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D as Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModel():    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32,kernel_size = (3,3),input_shape = (28,28,1),activation = 'relu',padding = 'same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Conv2D(64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation = 'relu'))\n",
    "    model.add(Dense(25,activation = 'softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier = generateModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                200768    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1625      \n",
      "=================================================================\n",
      "Total params: 258,137\n",
      "Trainable params: 258,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir = 'logs/SLR classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "27455/27455 [==============================] - 38s 1ms/step - loss: 1.6579 - acc: 0.4913\n",
      "Epoch 2/4\n",
      "27455/27455 [==============================] - 38s 1ms/step - loss: 0.2671 - acc: 0.9178\n",
      "Epoch 3/4\n",
      " 8400/27455 [========>.....................] - ETA: 26s - loss: 0.0828 - acc: 0.9810"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-41967f2d45b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\meeta\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train, batch_size = 100, epochs = 3, callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "# joblib.dump(classifier, 'saved_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(LOC):\n",
    "    lbl = y_test[LOC]\n",
    "    return list(lbl).index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13aafcc4668>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOC = 15\n",
    "print('Label:', getLabel(LOC))\n",
    "image = x_test[LOC]\n",
    "plt.imshow(image.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n"
     ]
    }
   ],
   "source": [
    "image = image.reshape((1,28,28,1))\n",
    "res = classifier.predict(image)\n",
    "res = list(res[0])\n",
    "mx = max(res)\n",
    "print('Prediction:',res.index(mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
